{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AQ9Pfc1NDtf",
        "outputId": "7efac5a3-6f23-4b4c-9740-9e928a3963de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHfD18aFNqYQ"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/My\\ Drive/Stock_Price_Prediction-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kTx9LybvP9pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3597d9-1229-4f28-cb14-e8f106f35d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAZSTqi1Ptzk",
        "outputId": "2a6511da-8087-43d0-8e47-4b41d4a7aeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "union_model = load_model(\"/content/Stock_Price_Prediction-main/python_script/saved_models/UnionBankOfIndia.h5\")\n",
        "boi_model = load_model(\"/content/Stock_Price_Prediction-main/python_script/saved_models/BankOfIndia_model.h5\")\n",
        "bob_model = load_model(\"/content/Stock_Price_Prediction-main/python_script/saved_models/BankOfBaroda.h5\")\n",
        "sbi_model = load_model(\"/content/Stock_Price_Prediction-main/python_script/saved_models/StateBankOfIndia_model.h5\")\n",
        "pnb_model = load_model(\"/content/Stock_Price_Prediction-main/python_script/saved_models/PunjabNationalBank.h5\")\n",
        "\n",
        "union_data = pd.read_csv(\"/content/Stock_Price_Prediction-main/Data/Bank_data/UNIONBANK_5Y.csv\")\n",
        "boi_data = pd.read_csv(\"/content/Stock_Price_Prediction-main/Data/Bank_data/BOI_5Y.csv\")\n",
        "bob_data = pd.read_csv(\"/content/Stock_Price_Prediction-main/Data/Bank_data/BANKBARODA_5Y.csv\")\n",
        "sbi_data = pd.read_csv(\"/content/Stock_Price_Prediction-main/Data/Bank_data/SBIN_5Y.csv\")\n",
        "pnb_data = pd.read_csv(\"/content/Stock_Price_Prediction-main/Data/Bank_data/PNB_5Y.csv\")\n",
        "\n",
        "allmodels = {'Union Bank of India': union_model, 'State Bank of India': sbi_model, 'Bank of India': boi_model, 'Bank of Baroda': bob_model, 'Punjab National Bank': pnb_model}\n",
        "stocks = {'Union Bank of India': union_data, 'State Bank of India': sbi_data, 'Bank of India': boi_data, 'Bank of Baroda': bob_data, 'Punjab National Bank': pnb_data}\n",
        "stocks_data = ('Union Bank of India', 'State Bank of India', 'Bank of India', 'Bank of Baroda', 'Punjab National Bank')\n",
        "\n",
        "\n",
        "\n",
        "n_steps = 30\n",
        "\n",
        "def choose_dataset(stocks, stocks_data, allmodels):\n",
        "    st.sidebar.subheader('Select the bank')\n",
        "    stock = st.sidebar.selectbox( \"\", stocks_data, key='1' )\n",
        "    check = st.sidebar.checkbox(\"Hide\", value=True, key='2')\n",
        "    \n",
        "    #st.sidebar.write(check)\n",
        "    for itr in stocks_data:\n",
        "        if stock==itr:\n",
        "            main_df=stocks[itr]\n",
        "            model=allmodels[itr]\n",
        "    return main_df, check, stock, model\n",
        "\n",
        "\n",
        "def about_section():\n",
        "    st.sidebar.subheader('Made By:')\n",
        "    st.sidebar.markdown(\"Atharva Bilonikar\")\n",
        "    st.sidebar.markdown(\"Harsh Chandra\")\n",
        "    st.sidebar.markdown(\"Vedant Dapolikar\")\n",
        "\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "\n",
        "\n",
        "def plot_predict(df, model, name):\n",
        "    \n",
        "    \n",
        "    df = df.drop([\"Open\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "    df = df.dropna()\n",
        "    Date = df[\"Date\"]\n",
        "    close = df[\"Close\"]\n",
        "    close = close.dropna()\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    tmp = scaler.fit(np.array(close).reshape(-1,1))\n",
        "    new_df = scaler.transform(np.array(close).reshape(-1,1))\n",
        "    \n",
        "    training_size=int(len(new_df)*0.67)\n",
        "    test_size=len(new_df)-training_size\n",
        "    train_data,test_data=new_df[:training_size],new_df[training_size:]\n",
        "    Date_train, Date_test = Date[:training_size], Date[training_size:]\n",
        "    \n",
        "    n_steps = 30\n",
        "    time_step=n_steps\n",
        "    X_train, Y_train = create_dataset(train_data, time_step)\n",
        "    X_test, Y_test = create_dataset(test_data, time_step)\n",
        "    print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
        "    X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
        "    print(X_train.shape, X_test.shape)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    train_predict=model.predict(X_train)\n",
        "    test_predict=model.predict(X_test)\n",
        "    print(train_predict.shape, test_predict.shape)\n",
        "    \n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    print(f'Train error - {mean_squared_error(train_predict, Y_train)*100}')\n",
        "    print(f'Test error - {mean_squared_error(test_predict, Y_test)*100}')\n",
        "    \n",
        "    train_predict=scaler.inverse_transform(train_predict)\n",
        "    test_predict=scaler.inverse_transform(test_predict)\n",
        "    X_train=X_train.reshape(-1, 1)\n",
        "    X_test=X_test.reshape(-1, 1)\n",
        "    close_train=scaler.inverse_transform(train_data)\n",
        "    close_test=scaler.inverse_transform(test_data)\n",
        "    close_train = close_train.reshape(-1)\n",
        "    close_test = close_test.reshape(-1)\n",
        "    prediction = test_predict.reshape((-1))\n",
        "    \n",
        "    trace1 = go.Scatter(\n",
        "        x = Date_train,\n",
        "        y = close_train,\n",
        "        mode = 'lines',\n",
        "        name = 'Data'\n",
        "    )\n",
        "    trace2 = go.Scatter(\n",
        "        x = Date_test[n_steps:],\n",
        "        y = prediction,\n",
        "        mode = 'lines',\n",
        "        name = 'Prediction'\n",
        "    )\n",
        "    trace3 = go.Scatter(\n",
        "        x = Date_test,\n",
        "        y = close_test,\n",
        "        mode='lines',\n",
        "        name = 'Ground Truth'\n",
        "    )\n",
        "    layout = go.Layout(\n",
        "        title = name,\n",
        "        xaxis = {'title' : \"Date\"},\n",
        "        yaxis = {'title' : \"Close\"}\n",
        "    )\n",
        "    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
        "    \n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "    #fig.show()\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "def plot_forecast_data(df, days, model, name):\n",
        "    \n",
        "    df = df.drop([\"Open\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "    df = df.dropna()\n",
        "    Date = df[\"Date\"]\n",
        "    close = df[\"Close\"]\n",
        "    close = close.dropna()\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    tmp = scaler.fit(np.array(close).reshape(-1,1))\n",
        "    new_df = scaler.transform(np.array(close).reshape(-1,1))\n",
        "    \n",
        "    \n",
        "    \n",
        "    test_data = close\n",
        "    test_data = scaler.transform(np.array(close).reshape(-1,1))\n",
        "    test_data = test_data.reshape((-1))\n",
        "    \n",
        "    def predict(num_prediction, model):\n",
        "        prediction_list = test_data[-n_steps:]\n",
        "        \n",
        "        for _ in range(num_prediction):\n",
        "            x = prediction_list[-n_steps:]\n",
        "            x = x.reshape((1, n_steps, 1))\n",
        "            out = model.predict(x)[0][0]\n",
        "            prediction_list = np.append(prediction_list, out)\n",
        "        prediction_list = prediction_list[n_steps-1:]\n",
        "            \n",
        "        return prediction_list\n",
        "        \n",
        "    def predict_dates(num_prediction):\n",
        "        last_date = df['Date'].values[-1]\n",
        "        prediction_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()\n",
        "        return prediction_dates\n",
        "    \n",
        "    num_prediction =days\n",
        "    forecast = predict(num_prediction, model)\n",
        "    forecast_dates = predict_dates(num_prediction)\n",
        "    forecast = forecast.reshape(1, -1)\n",
        "    forecast = scaler.inverse_transform(forecast)\n",
        "    forecast\n",
        "    test_data = test_data.reshape(1, -1)\n",
        "    test_data = scaler.inverse_transform(test_data)\n",
        "    test_data = test_data.reshape(-1)\n",
        "    forecast = forecast.reshape(-1)\n",
        "    res = dict(zip(forecast_dates, forecast))\n",
        "    date = df[\"Date\"]\n",
        "    trace1 = go.Scatter(\n",
        "        x = date,\n",
        "        y = test_data,\n",
        "        mode = 'lines',\n",
        "        name = 'Data'\n",
        "    )\n",
        "    trace2 = go.Scatter(\n",
        "        x = forecast_dates,\n",
        "        y = forecast,\n",
        "        mode = 'lines',\n",
        "        name = 'Prediction'\n",
        "    )\n",
        "    layout = go.Layout(\n",
        "    title = name,\n",
        "    xaxis = {'title' : \"Date\"},\n",
        "    yaxis = {'title' : \"Close\"}\n",
        "    )\n",
        "    \n",
        "    fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
        "    st.plotly_chart(fig)\n",
        "    #fig.show()\n",
        "    choose_date = st.selectbox(\"Date\", forecast_dates)\n",
        "    for itr in res:\n",
        "        if choose_date==itr:\n",
        "            res_price=res[itr]\n",
        "    st.write(f\"On {choose_date} the stock price will be Rs. {res_price}\")\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def plot_raw_data(data):\n",
        "    \n",
        "   \tfig = go.Figure()\n",
        "   \tfig.add_trace(go.Scatter(x=data['Date'], y=data['Open'], name=\"stock_open\"))\n",
        "   \tfig.add_trace(go.Scatter(x=data['Date'], y=data['Close'], name=\"stock_close\"))\n",
        "   \tfig.layout.update( xaxis_rangeslider_visible=True)\n",
        "   \tst.plotly_chart(fig)\n",
        "    \t\n",
        "\n",
        "def landing_ui():\n",
        "    st.header(\"Welcome to Stock Price Predictor\")\n",
        "    st.write(\"\")\n",
        "    from PIL import Image\n",
        "    image = Image.open('/content/nick-chong-N__BnvQ_w18-unsplash.jpg')\n",
        "    st.image(image)\n",
        "    st.write(\"\")\n",
        "    st.write(\"This is our Mini Project of 4th semester\")\n",
        "    st.write(\"As the model is trained with data having time steps of 30 days so it will give its best results for a forecast till 30 days \")\n",
        "    st.write(\"\")\n",
        "    st.write(\"To see the data representation please uncheck the hide button in the sidebar\")\n",
        "    st.write(\"\")\n",
        "    st.write(\"Share market investments are subject to market risks, read all scheme related documents carefully. The NAVs of the schemes may go up or down depending upon the factors and forces affecting the securities market including the fluctuations in the interest rates. The past performance of the stocks is not necessarily indicative of future performance of the schemes.\")\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    st.sidebar.subheader(\"Stock Market Predictor\")\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    temp, check, name, model=choose_dataset(stocks, stocks_data, allmodels)\n",
        "    #about_section()\n",
        "    #print(temp)\n",
        "    if not check:\n",
        "        st.header(f\"Analyzing {name}'s stock data\")\n",
        "        st.subheader(\"Raw Data\")\n",
        "        st.write(temp)\n",
        "        \n",
        "        \n",
        "        st.subheader(\"Raw Data - Visualized\")\n",
        "        plot_raw_data(temp)\n",
        "        st.subheader(\"Predicted data\")\n",
        "        plot_predict(temp, model, name)\n",
        "        st.sidebar.subheader(\"Forecasted Data\")\n",
        "        forecast_check = st.sidebar.checkbox(\"See the results\", value=False)\n",
        "        about_section()\n",
        "        if forecast_check:\n",
        "            forecast = st.slider(\"Days to forecast\",min_value=30,max_value=100,step=5)\n",
        "            st.subheader(\"Forecasted data\")\n",
        "            \n",
        "            plot_forecast_data(temp, forecast, model, name)\n",
        "    else:\n",
        "        landing_ui()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfyptJaeSRsQ",
        "outputId": "01dbbf4b-57ba-48fe-e12c-45280be67b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 3.128s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DMwfx_xnVgXW"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGAlLhTsVh6V",
        "outputId": "4c097e8b-ed86-4f8d-dbca-b9a6c5d7bd30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.295s\n",
            "your url is: https://nine-windows-matter-34-32-156-123.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}